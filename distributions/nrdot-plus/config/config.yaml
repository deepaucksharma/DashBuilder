# NRDOT-Plus Production Configuration
# Version: 4.2.0 - Consolidated, tested configuration
# Combines minimal working config with essential NRDOT features

extensions:
  health_check:
    endpoint: "0.0.0.0:13133"
    path: "/health"
    
  file_storage:
    directory: /var/lib/nrdot-plus/storage
    timeout: 10s
    
  memory_ballast:
    size_mib: 64

receivers:
  # Host metrics with comprehensive process discovery
  hostmetrics:
    collection_interval: ${env:NRDOT_COLLECTION_INTERVAL:-60s}
    root_path: ${env:HOST_PROC:-/proc}
    scrapers:
      process:
        mute_process_name_error: true
        mute_process_exe_error: true
        mute_process_io_error: true
        metrics:
          process.cpu.time:
            enabled: true
          process.memory.physical_usage:
            enabled: true
          process.memory.virtual_usage:
            enabled: true
          process.disk.io:
            enabled: true
          process.threads:
            enabled: true
          process.open_file_descriptors:
            enabled: true
      
      cpu:
        metrics:
          system.cpu.utilization:
            enabled: true
          system.cpu.time:
            enabled: true
          system.cpu.logical.count:
            enabled: true
      
      memory:
        metrics:
          system.memory.utilization:
            enabled: true
          system.memory.usage:
            enabled: true
      
      disk:
        metrics:
          system.disk.io:
            enabled: true
          system.disk.operations:
            enabled: true
      
      network:
        metrics:
          system.network.io:
            enabled: true
          system.network.packets:
            enabled: true
          system.network.errors:
            enabled: true
      
      load:
        metrics:
          system.cpu.load_average.1m:
            enabled: true
          system.cpu.load_average.5m:
            enabled: true
          system.cpu.load_average.15m:
            enabled: true

  # Internal metrics for self-monitoring
  prometheus/internal:
    config:
      scrape_configs:
        - job_name: 'otelcol'
          scrape_interval: 10s
          static_configs:
            - targets: ['localhost:8888']

processors:
  # Memory protection (must be first)
  memory_limiter:
    check_interval: 1s
    limit_mib: ${env:NRDOT_MEMORY_LIMIT_MB:-512}
    spike_limit_mib: ${env:NRDOT_MEMORY_SPIKE_MB:-128}

  # Resource detection
  resourcedetection:
    detectors: [env, system, os]
    timeout: 5s
    override: false

  # Add NRDOT metadata and service identification
  attributes/nrdot_meta:
    actions:
      - key: service.name
        value: "nrdot-plus-host"
        action: insert
      - key: nrdot.version
        value: "4.2.0"
        action: upsert
      - key: nrdot.distribution
        value: "plus"
        action: upsert
      - key: nrdot.experiment.ring
        value: ${env:NRDOT_RING:-"0"}
        action: upsert
      - key: nrdot.profile.active
        value: ${env:NRDOT_ACTIVE_PROFILE:-"balanced"}
        action: upsert
      - key: host.name
        from_attribute: host.name
        action: insert

  # CPU utilization calculation (rate from cumulative)
  metricstransform/cpu_utilization:
    transforms:
      - include: process.cpu.time
        action: insert
        new_name: process.cpu.utilization
        operations:
          - action: aggregate_labels
            label_set: []
            aggregation_type: rate
          - action: experimental_scale_value
            scale: 100.0

  # Memory conversion to MB for easier reading
  metricstransform/memory_mb:
    transforms:
      - include: process.memory.physical_usage
        action: insert
        new_name: process.memory.physical_usage_mb
        operations:
          - action: experimental_scale_value
            scale: 0.000000953674  # Bytes to MB

  # Process classification and tier assignment
  attributes/process_classification:
    actions:
      # Initialize defaults
      - key: process.tier
        value: 6
        action: insert
      - key: process.importance
        value: 0.3
        action: insert
      - key: process.classification
        value: "other"
        action: insert

  # Enhanced process classification using transform
  transform/tier_assignment:
    error_mode: ignore
    metric_statements:
      - context: datapoint
        statements:
          # Tier 1: Critical System (1.0)
          - set(attributes["process.tier"], 1) where IsMatch(resource.attributes["process.executable.name"], "^(init|systemd|kernel|sshd)$")
          - set(attributes["process.importance"], 1.0) where attributes["process.tier"] == 1
          - set(attributes["process.classification"], "critical_system") where attributes["process.tier"] == 1
          
          # Tier 2: Databases (0.9)
          - set(attributes["process.tier"], 2) where IsMatch(resource.attributes["process.executable.name"], "(postgres|mysql|mongo|redis|cassandra|elastic)")
          - set(attributes["process.importance"], 0.9) where attributes["process.tier"] == 2
          - set(attributes["process.classification"], "database") where attributes["process.tier"] == 2
          
          # Tier 3: Web Servers (0.8)
          - set(attributes["process.tier"], 3) where IsMatch(resource.attributes["process.executable.name"], "(nginx|apache|httpd|haproxy|envoy)")
          - set(attributes["process.importance"], 0.8) where attributes["process.tier"] == 3
          - set(attributes["process.classification"], "web_server") where attributes["process.tier"] == 3
          
          # Tier 4: Applications (0.6)
          - set(attributes["process.tier"], 4) where IsMatch(resource.attributes["process.executable.name"], "(java|python|node|ruby|dotnet|php)")
          - set(attributes["process.importance"], 0.6) where attributes["process.tier"] == 4
          - set(attributes["process.classification"], "application") where attributes["process.tier"] == 4

  # Generate NRDOT KPI metrics
  metricstransform/nrdot_kpis:
    transforms:
      # Total process count
      - include: process.cpu.time
        action: insert
        new_name: nrdot_summary_total_processes
        operations:
          - action: aggregate_labels
            label_set: []
            aggregation_type: count
      
      # Process count by tier
      - include: process.cpu.time
        action: insert
        new_name: nrdot_tier_process_count
        operations:
          - action: aggregate_labels
            label_set: ["process.tier", "process.classification"]
            aggregation_type: count
      
      # Total series estimate (6 metrics per process average)
      - include: nrdot_summary_total_processes
        action: insert
        new_name: nrdot_summary_total_series
        operations:
          - action: experimental_scale_value
            scale: 6.0

  # Cost calculation ($0.25 per million datapoints)
  metricstransform/cost_calculation:
    transforms:
      - include: nrdot_summary_total_series
        action: insert
        new_name: nrdot_cost_estimate_hourly
        operations:
          - action: experimental_scale_value
            scale: 0.000015  # Series * 60 datapoints/hour * $0.25/1M = series * 0.000015

  # Coverage metrics
  metricstransform/coverage:
    transforms:
      - include: process.cpu.time
        action: insert
        new_name: nrdot_coverage_percentage
        operations:
          - action: aggregate_labels
            label_set: []
            aggregation_type: count
          - action: experimental_scale_value
            scale: 1.0  # Will be adjusted by control loop

  # Experiment tracking
  metricstransform/experiments:
    transforms:
      # Control group (ring 0)
      - include: process.cpu.time
        action: insert
        new_name: nrdot_experiment_control_processes
        operations:
          - action: aggregate_labels
            label_set: []
            aggregation_type: count

  # Intelligent filtering based on thresholds and importance
  filter/smart_sampling:
    error_mode: ignore
    metrics:
      datapoint:
        # Always keep tier 1-2 (critical + database)
        - 'attributes["process.tier"] <= 2'
        # Keep high-importance processes
        - 'attributes["process.importance"] >= ${env:NRDOT_MIN_IMPORTANCE:-0.5}'
        # Apply resource thresholds for others
        - 'name != "process.cpu.utilization" or value >= ${env:NRDOT_CPU_THRESHOLD:-1.0}'
        - 'name != "process.memory.physical_usage" or value >= ${env:NRDOT_MEMORY_THRESHOLD_MB:-10} * 1048576'

  # Batch processing for efficiency
  batch:
    send_batch_size: ${env:NRDOT_BATCH_SIZE:-1000}
    timeout: ${env:NRDOT_BATCH_TIMEOUT:-10s}
    send_batch_max_size: ${env:NRDOT_BATCH_MAX_SIZE:-2000}

exporters:
  # New Relic OTLP HTTP exporter
  otlphttp/newrelic:
    endpoint: ${env:OTEL_EXPORTER_OTLP_ENDPOINT:-https://otlp.nr-data.net}
    headers:
      api-key: ${env:NEW_RELIC_LICENSE_KEY}
    compression: gzip
    timeout: 30s
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s
    sending_queue:
      enabled: true
      num_consumers: 4
      queue_size: 1000

  # Prometheus for local monitoring and debugging
  prometheus:
    endpoint: "0.0.0.0:8888"
    namespace: nrdot
    const_labels:
      distribution: "plus"
      version: "4.2.0"
    resource_to_telemetry_conversion:
      enabled: true

  # Debug logging (disabled in production)
  logging:
    loglevel: ${env:OTEL_DEBUG_LOG_LEVEL:-debug}
    sampling_initial: 5
    sampling_thereafter: 100

service:
  extensions: [health_check, file_storage, memory_ballast]
  
  pipelines:
    # Main metrics pipeline with full NRDOT processing
    metrics/main:
      receivers: [hostmetrics]
      processors:
        - memory_limiter
        - resourcedetection
        - attributes/nrdot_meta
        - metricstransform/cpu_utilization
        - metricstransform/memory_mb
        - attributes/process_classification
        - transform/tier_assignment
        - metricstransform/nrdot_kpis
        - metricstransform/cost_calculation
        - metricstransform/coverage
        - metricstransform/experiments
        - filter/smart_sampling
        - batch
      exporters: 
        - otlphttp/newrelic
        - prometheus

    # Internal monitoring pipeline
    metrics/internal:
      receivers: [prometheus/internal]
      processors:
        - memory_limiter
        - batch
      exporters: 
        - logging

  telemetry:
    logs:
      level: ${env:OTEL_LOG_LEVEL:-info}
      encoding: json
      output_paths:
        - stdout
        - /var/log/nrdot-plus/collector.log
    
    metrics:
      level: detailed
      address: 0.0.0.0:8889