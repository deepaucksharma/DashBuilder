# Aggressive NRDOT Configuration - Maximum Optimization
# Only collects metrics for critical processes

extensions:
  health_check:
    endpoint: "0.0.0.0:13133"
    path: "/health"

receivers:
  hostmetrics:
    collection_interval: 120s  # Less frequent collection
    scrapers:
      process:
        # Include only specific critical processes
        include:
          names:
            - "java"
            - "node"
            - "python"
            - "nginx"
            - "apache"
            - "mysql"
            - "postgres"
            - "redis"
            - "docker"
            - "kubelet"
          match_type: strict
        
        mute_process_name_error: true
        mute_process_exe_error: true
        mute_process_io_error: true
    
      # Minimal system metrics
      cpu:
      memory:
      load:

  prometheus:
    config:
      scrape_configs:
        - job_name: 'otel-collector'
          scrape_interval: 60s
          static_configs:
            - targets: ['0.0.0.0:8888']

processors:
  batch:
    timeout: 30s  # Larger batches
    send_batch_size: 5000
    
  # Aggressive filtering - only keep top processes
  filter/metrics:
    metrics:
      metric:
        - 'name == "process.cpu.time" and value < 10'  # Remove processes with < 10s CPU time
        - 'name == "process.memory.physical_usage" and value < 10485760'  # Remove processes < 10MB RAM
    
  # Top K filtering - keep only top 20 processes
  transform/topk:
    metric_statements:
      - context: metric
        statements:
          - limit(20) where name == "process.cpu.time"
          - limit(20) where name == "process.memory.physical_usage"
    
  resource:
    attributes:
      - key: experiment.name
        value: aggressive
        action: insert
      - key: experiment.profile
        value: maximum-optimization
        action: insert
      - key: service.name
        value: nrdot-aggressive
        action: insert
      - key: service.version
        value: "2.0"
        action: insert

  memory_limiter:
    check_interval: 1s
    limit_mib: 128
    spike_limit_mib: 32

exporters:
  otlp:
    endpoint: "${NEW_RELIC_OTLP_ENDPOINT}"
    headers:
      api-key: "${NEW_RELIC_API_KEY}"
    compression: gzip
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s
    
  logging:
    loglevel: warn  # Less logging
    sampling_initial: 1
    sampling_thereafter: 100

  prometheus:
    endpoint: "0.0.0.0:8888"
    metric_expiration: 10m

service:
  pipelines:
    metrics:
      receivers: [hostmetrics, prometheus]
      processors: [memory_limiter, filter/metrics, transform/topk, batch, resource]
      exporters: [otlp, prometheus]  # No logging in pipeline
      
  extensions: [health_check]
  
  telemetry:
    logs:
      level: warn
    metrics:
      level: basic
      address: 0.0.0.0:8888