# OpenTelemetry Collector Configuration with Experiment Tracking

receivers:
  # Host metrics
  hostmetrics:
    collection_interval: 15s
    scrapers:
      cpu:
      memory:
      process:
      disk:
      filesystem:
      network:
      load:

  # OTLP receiver
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

processors:
  # Batch processor
  batch:
    timeout: 10s
    send_batch_size: 1000

  # Memory limiter
  memory_limiter:
    check_interval: 1s
    limit_mib: 512

  # Resource detection for infrastructure context
  resourcedetection:
    detectors: [env, system, docker]
    timeout: 5s

  # Add all experiment tracking attributes
  attributes/experiment:
    actions:
      # Service identification
      - key: service.name
        value: nrdot
        action: upsert
      - key: service.version
        value: "2.0"
        action: upsert
      
      # Experiment identifiers
      - key: experiment.id
        value: ${EXPERIMENT_ID:-exp-default}
        action: upsert
      - key: experiment.name
        value: ${EXPERIMENT_NAME:-nrdot-optimization-test}
        action: upsert
      - key: experiment.run.id
        value: ${EXPERIMENT_RUN_ID:-run-default}
        action: upsert
      - key: experiment.version
        value: ${EXPERIMENT_VERSION:-1.0.0}
        action: upsert
      - key: experiment.phase
        value: ${EXPERIMENT_PHASE:-optimization}
        action: upsert
      
      # Configuration details
      - key: config.profile
        value: ${NRDOT_PROFILE:-balanced}
        action: upsert
      - key: config.cpu.threshold
        value: ${TARGET_CPU_THRESHOLD:-70}
        action: upsert
      - key: config.memory.threshold
        value: ${TARGET_MEMORY_THRESHOLD:-80}
        action: upsert
      - key: config.cost.target
        value: ${TARGET_COST_REDUCTION:-0.70}
        action: upsert
      - key: config.coverage.target
        value: ${CRITICAL_PROCESS_THRESHOLD:-0.95}
        action: upsert
      - key: config.process.min_cpu
        value: ${MIN_CPU_THRESHOLD:-0.1}
        action: upsert
      - key: config.process.min_memory
        value: ${MIN_MEMORY_THRESHOLD:-10485760}
        action: upsert
      
      # Business context
      - key: team
        value: ${TEAM_NAME:-platform}
        action: upsert
      - key: owner
        value: ${OWNER:-nrdot}
        action: upsert
      - key: cost.center
        value: ${COST_CENTER:-engineering}
        action: upsert
      - key: project
        value: ${PROJECT_NAME:-telemetry-optimization}
        action: upsert
      
      # Deployment context
      - key: deployment.env
        value: ${DEPLOYMENT_ENV:-docker}
        action: upsert
      - key: cluster.name
        value: ${CLUSTER_NAME:-local}
        action: upsert
      - key: region
        value: ${REGION:-us-east-1}
        action: upsert

  # Transform metrics to add NRDOT namespace and KPIs
  metricstransform:
    transforms:
      # System metrics
      - include: system.cpu.utilization
        match_type: strict
        action: insert
        new_name: nrdot.cpu.utilization
      - include: system.memory.utilization
        match_type: strict
        action: insert
        new_name: nrdot.memory.utilization
      
      # Process metrics
      - include: process.cpu.utilization
        match_type: strict
        action: insert
        new_name: nrdot.process.cpu.utilization
      - include: process.memory.usage
        match_type: strict
        action: insert
        new_name: nrdot.process.memory.usage
      
      # Add experiment phase to process metrics
      - include: process.*
        match_type: regexp
        action: update
        operations:
          - action: add_label
            new_label: experiment.phase
            new_value: ${EXPERIMENT_PHASE:-optimization}

  # Filter processes based on thresholds
  filter/processes:
    metrics:
      include:
        match_type: regexp
        metric_names:
          - process.*
        resource_attributes:
          - key: process.executable.name
            value: ${PROCESS_INCLUDE_PATTERN:-.+}
      exclude:
        match_type: regexp
        resource_attributes:
          - key: process.executable.name
            value: ${PROCESS_EXCLUDE_PATTERN:-(kernel|systemd-|ssh-agent|kworker)}

exporters:
  # New Relic OTLP exporter
  otlp/newrelic:
    endpoint: "otlp.nr-data.net:4317"
    headers:
      "api-key": ${NEW_RELIC_LICENSE_KEY}
    compression: gzip
    tls:
      insecure: false
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 60s
      max_elapsed_time: 10m

  # Debug exporter for local testing
  debug:
    verbosity: normal
    sampling_initial: 5
    sampling_thereafter: 100

  # Prometheus exporter for local monitoring
  prometheus:
    endpoint: "0.0.0.0:8888"
    namespace: nrdot
    const_labels:
      experiment_id: ${EXPERIMENT_ID:-exp-default}
      profile: ${NRDOT_PROFILE:-balanced}

  # File exporter for experiment data backup
  file:
    path: /tmp/experiment-metrics-${EXPERIMENT_ID}.json
    rotation:
      max_megabytes: 100
      max_days: 7
      max_backups: 5

extensions:
  # Health check
  health_check:
    endpoint: 0.0.0.0:13133
    path: "/health"
    check_collector_pipeline:
      enabled: true
      interval: 5s
      exporter_failure_threshold: 5

  # Performance profiler
  pprof:
    endpoint: 0.0.0.0:1777

  # zPages for debugging
  zpages:
    endpoint: 0.0.0.0:55679

service:
  telemetry:
    logs:
      level: ${LOG_LEVEL:-info}
      development: false
      encoding: json
    metrics:
      level: detailed
      address: 0.0.0.0:8888

  extensions: [health_check, pprof, zpages]
  
  pipelines:
    # Main metrics pipeline with all processors
    metrics:
      receivers: [hostmetrics, otlp]
      processors: 
        - memory_limiter
        - batch
        - resourcedetection
        - attributes/experiment
        - filter/processes
        - metricstransform
      exporters: [otlp/newrelic, prometheus, debug, file]